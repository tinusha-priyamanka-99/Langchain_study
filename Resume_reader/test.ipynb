{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_openai import OpenAI\n",
    "from langchain_community.document_loaders import TextLoader, DirectoryLoader\n",
    "from langchain.embeddings import HuggingFaceInstructEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.chains import RetrievalQA \n",
    "from langchain.prompts import PromptTemplate\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load INSTRUCTOR_Transformer\n",
      "max_seq_length  512\n"
     ]
    }
   ],
   "source": [
    "llm = OpenAI(temperature=0.6, max_tokens=500)\n",
    "\n",
    "folder_path = 'D:\\\\Data Science\\\\Generative_AI\\\\Resume reader'\n",
    "loader = DirectoryLoader(folder_path, glob='*.txt', loader_cls=TextLoader)\n",
    "documents = loader.load()\n",
    "\n",
    "embeddings = HuggingFaceInstructEmbeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectordb = FAISS.from_documents(\n",
    "    documents=documents,\n",
    "    embedding=embeddings\n",
    ")\n",
    "\n",
    "retriever = vectordb.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer:  {'query': 'Mention the required academic qualification', 'result': \" for Senior Data Scientist\\n\\nMaster's Degree in Computer Science, Statistics, Math, Operations Research, Economics, or a related field.\"}\n"
     ]
    }
   ],
   "source": [
    "prompt_template = \"\"\"Given the following context and a question, generate an answer using minimum number of words based on this context only.\n",
    "    In the answer try to provide as much text as possible from \"response\" section in the source document context without making much changes.\n",
    "    If the answer is not found in the context, kindly state \"I don't know.\" Don't try to make up an answer.\n",
    "\n",
    "    CONTEXT: {context}\n",
    "\n",
    "    QUESTION: {question}\"\"\"\n",
    "\n",
    "PROMPT = PromptTemplate(\n",
    "        template=prompt_template, \n",
    "        input_variables=[\"context\", \"question\"]\n",
    "    )\n",
    "\n",
    "chain = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    chain_type=\"stuff\",\n",
    "    retriever=retriever,\n",
    "    input_key=\"query\",\n",
    "    return_source_documents=False,\n",
    "    chain_type_kwargs={\"prompt\": PROMPT})\n",
    "\n",
    "result = chain(\"Mention the required academic qualification\")\n",
    "print(\"Answer: \",result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load INSTRUCTOR_Transformer\n",
      "max_seq_length  512\n",
      "       File                             Job title        Experienced years  \\\n",
      "0  JD_1.txt                         [\\n\\nAnalyst]         [\\n\\n1-2 years.]   \n",
      "1  JD_2.txt           [\\n\\nSenior Data Scientist]  [\\n\\nAt least 2 years.]   \n",
      "2  JD_3.txt  [\\n\\nBusiness Development Associate]      [\\n\\nI don't know.]   \n",
      "3  JD_4.txt                  [\\n\\nData Scientist]  [\\n\\nAt least 2 years.]   \n",
      "4  JD_5.txt                 [\\n\\nProcess Analyst]          [\\n\\n0-3 years]   \n",
      "\n",
      "                              Academic Qualification  \n",
      "0  [\\n\\nGraduate in science/business/accounting o...  \n",
      "1  [\\n\\nMaster's Degree in Computer Science, Stat...  \n",
      "2         [\\nBusiness, Marketing, or related field.]  \n",
      "3  [\\n\\nMaster's Degree in Computer Science, Stat...  \n",
      "4  [\\n\\nAny Graduate (Arts/science/commerce/busin...  \n",
      "\n",
      "Academic Qualification:\n",
      "['\\n\\nGraduate in science/business/accounting or CIMA/CA.']\n",
      "[\"\\n\\nMaster's Degree in Computer Science, Statistics, Math, or related field.\"]\n",
      "['\\nBusiness, Marketing, or related field.']\n",
      "[\"\\n\\nMaster's Degree in Computer Science, Statistics, or related field.\"]\n",
      "['\\n\\nAny Graduate (Arts/science/commerce/business)']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "from langchain_openai import OpenAI\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_community.document_loaders import DirectoryLoader, TextLoader\n",
    "from langchain_community.embeddings import HuggingFaceInstructEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "llm = OpenAI(temperature=0.6, max_tokens=500)\n",
    "\n",
    "folder_path = 'D:\\\\Data Science\\\\Generative_AI\\\\Resume reader'\n",
    "loader = DirectoryLoader(folder_path, glob='*.txt', loader_cls=TextLoader)\n",
    "documents = loader.load()\n",
    "\n",
    "embeddings = HuggingFaceInstructEmbeddings()\n",
    "\n",
    "prompt_template = \"\"\"Given the following context and a question, generate an answer using minimum number of words based on this context only.\n",
    "    In the answer try to provide as much text as possible from \"response\" section in the source document context without making much changes.\n",
    "    If the answer is not found in the context, kindly state \"I don't know.\" Don't try to make up an answer.\n",
    "\n",
    "    CONTEXT: {context}\n",
    "\n",
    "    QUESTION: {question}\"\"\"\n",
    "\n",
    "PROMPT = PromptTemplate(\n",
    "    template=prompt_template, \n",
    "    input_variables=[\"context\", \"question\"]\n",
    ")\n",
    "\n",
    "questions = [\n",
    "    \"Mention the job title using less than four words.\",\n",
    "    \"Mention the number of experience years needed for positions using less than six words.\",\n",
    "    \"Mention the academic qualification using less than ten words.\"\n",
    "]\n",
    "\n",
    "\n",
    "all_results = []\n",
    "\n",
    "for doc in documents:\n",
    "    vectordb = FAISS.from_documents(\n",
    "        documents=[doc],\n",
    "        embedding=embeddings\n",
    "    )\n",
    "\n",
    "    retriever = vectordb.as_retriever()\n",
    "\n",
    "    chain = RetrievalQA.from_chain_type(\n",
    "        llm=llm,\n",
    "        chain_type=\"stuff\",\n",
    "        retriever=retriever,\n",
    "        input_key=\"query\",\n",
    "        return_source_documents=False,\n",
    "        chain_type_kwargs={\"prompt\": PROMPT}\n",
    "    )\n",
    "\n",
    "    # Dictionary to store the results for this document\n",
    "    results = {\n",
    "        \"Job title\": [],\n",
    "        \"Experienced years\": [],\n",
    "        \"Academic Qualification\": []\n",
    "    }\n",
    "\n",
    "    # Query each question and store the results\n",
    "    for question in questions:\n",
    "        result = chain({\"query\": question})\n",
    "        if question.startswith(\"Mention the job title\"):\n",
    "            results[\"Job title\"].append(result['result'])\n",
    "        elif question.startswith(\"Mention the number of experience years\"):\n",
    "            results[\"Experienced years\"].append(result['result'])\n",
    "        elif question.startswith(\"Mention the academic qualification\"):\n",
    "            results[\"Academic Qualification\"].append(result['result'])\n",
    "\n",
    "    # Add the results for this document to the list of all results\n",
    "    all_results.append(results)\n",
    "\n",
    "# Convert all results to a DataFrame\n",
    "data = {\n",
    "    \"File\": [],\n",
    "    \"Job title\": [],\n",
    "    \"Experienced years\": [],\n",
    "    \"Academic Qualification\": []\n",
    "}\n",
    "\n",
    "for i, result in enumerate(all_results):\n",
    "    data[\"File\"].append(f'JD_{i+1}.txt')\n",
    "    data[\"Job title\"].append(result[\"Job title\"])\n",
    "    data[\"Experienced years\"].append(result[\"Experienced years\"])\n",
    "    data[\"Academic Qualification\"].append(result[\"Academic Qualification\"])\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Print the DataFrame\n",
    "print(df)\n",
    "\n",
    "print(\"\\nAcademic Qualification:\")\n",
    "for qualification in df[\"Academic Qualification\"]:\n",
    "    print(qualification)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of documents loaded: 5\n",
      "Document metadata: {'source': 'D:\\\\Data Science\\\\Generative_AI\\\\Resume reader\\\\Anthony Davies_Resume.pdf', 'file_path': 'D:\\\\Data Science\\\\Generative_AI\\\\Resume reader\\\\Anthony Davies_Resume.pdf', 'page': 0, 'total_pages': 1, 'format': 'PDF 1.7', 'title': '', 'author': 'Turbo', 'subject': '', 'keywords': '', 'creator': 'Microsoft® Word for Microsoft 365', 'producer': 'Microsoft® Word for Microsoft 365', 'creationDate': \"D:20240302172612+05'30'\", 'modDate': \"D:20240302172612+05'30'\", 'trapped': ''}\n",
      "Document metadata: {'source': 'D:\\\\Data Science\\\\Generative_AI\\\\Resume reader\\\\Christoper Morgan_Resume.pdf', 'file_path': 'D:\\\\Data Science\\\\Generative_AI\\\\Resume reader\\\\Christoper Morgan_Resume.pdf', 'page': 0, 'total_pages': 1, 'format': 'PDF 1.7', 'title': '', 'author': 'Turbo', 'subject': '', 'keywords': '', 'creator': 'Microsoft® Word for Microsoft 365', 'producer': 'Microsoft® Word for Microsoft 365', 'creationDate': \"D:20240302170323+05'30'\", 'modDate': \"D:20240302170323+05'30'\", 'trapped': ''}\n",
      "Document metadata: {'source': 'D:\\\\Data Science\\\\Generative_AI\\\\Resume reader\\\\Layney Spencer_Resume.pdf', 'file_path': 'D:\\\\Data Science\\\\Generative_AI\\\\Resume reader\\\\Layney Spencer_Resume.pdf', 'page': 0, 'total_pages': 2, 'format': 'PDF 1.3', 'title': 'Assistant Director', 'author': '', 'subject': '', 'keywords': '', 'creator': 'react-pdf', 'producer': 'react-pdf', 'creationDate': 'D:20220201110147Z', 'modDate': '', 'trapped': ''}\n",
      "Document metadata: {'source': 'D:\\\\Data Science\\\\Generative_AI\\\\Resume reader\\\\Layney Spencer_Resume.pdf', 'file_path': 'D:\\\\Data Science\\\\Generative_AI\\\\Resume reader\\\\Layney Spencer_Resume.pdf', 'page': 1, 'total_pages': 2, 'format': 'PDF 1.3', 'title': 'Assistant Director', 'author': '', 'subject': '', 'keywords': '', 'creator': 'react-pdf', 'producer': 'react-pdf', 'creationDate': 'D:20220201110147Z', 'modDate': '', 'trapped': ''}\n",
      "Document metadata: {'source': 'D:\\\\Data Science\\\\Generative_AI\\\\Resume reader\\\\Susan Williams_Resume.pdf', 'file_path': 'D:\\\\Data Science\\\\Generative_AI\\\\Resume reader\\\\Susan Williams_Resume.pdf', 'page': 0, 'total_pages': 1, 'format': 'PDF 1.7', 'title': '', 'author': 'Turbo', 'subject': '', 'keywords': '', 'creator': 'Microsoft® Word for Microsoft 365', 'producer': 'Microsoft® Word for Microsoft 365', 'creationDate': \"D:20240302172843+05'30'\", 'modDate': \"D:20240302172843+05'30'\", 'trapped': ''}\n",
      "load INSTRUCTOR_Transformer\n",
      "max_seq_length  512\n",
      "                           File                 Job title  \\\n",
      "0     Anthony Davies_Resume.pdf       [\\n\\nWeb Developer]   \n",
      "1  Christoper Morgan_Resume.pdf       [\\n\\nWeb Developer]   \n",
      "2     Layney Spencer_Resume.pdf  [\\n\\nAssistant Director]   \n",
      "3     Susan Williams_Resume.pdf       [\\n\\nStore Manager]   \n",
      "\n",
      "          Experienced years                             Academic Qualification  \n",
      "0             [\\n\\n2 years]  [\\n\\nBachelor of Science in Computer Informati...  \n",
      "1         [\\n\\nFour years.]  [\\n\\nBachelor of Science in Computer Informati...  \n",
      "2            [\\n\\n14 years]         [\\n\\nMaster's in Business Administration.]  \n",
      "3  [\\n\\n4 years and 1 year]  [\\n\\nBachelor of Science in Automotive Technol...  \n",
      "\n",
      "Academic Qualification:\n",
      "['\\n\\nBachelor of Science in Computer Information Systems.']\n",
      "['\\n\\nBachelor of Science in Computer Information Systems.']\n",
      "[\"\\n\\nMaster's in Business Administration.\"]\n",
      "['\\n\\nBachelor of Science in Automotive Technology.']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "from langchain_openai import OpenAI\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_community.document_loaders import DirectoryLoader, PyMuPDFLoader\n",
    "from langchain_community.embeddings import HuggingFaceInstructEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "llm = OpenAI(temperature=0, max_tokens=500)\n",
    "\n",
    "folder_path = 'D:\\\\Data Science\\\\Generative_AI\\\\Resume reader'\n",
    "loader = DirectoryLoader(folder_path, glob='*.pdf', loader_cls=PyMuPDFLoader)\n",
    "documents = loader.load()\n",
    "\n",
    "# Print the loaded documents for debugging\n",
    "print(f\"Number of documents loaded: {len(documents)}\")\n",
    "for doc in documents:\n",
    "    print(f\"Document metadata: {doc.metadata}\")\n",
    "\n",
    "embeddings = HuggingFaceInstructEmbeddings()\n",
    "\n",
    "prompt_template = \"\"\"\n",
    "Given the following context and a question, generate an answer using minimum number of words based on this context only.\n",
    "In the answer try to provide as much text as possible from \"response\" section in the source document context without making much changes.\n",
    "If the answer is not found in the context, kindly state \"I don't know.\" Don't try to make up an answer.\n",
    "\n",
    "CONTEXT: {context}\n",
    "\n",
    "QUESTION: {question}\"\"\"\n",
    "\n",
    "PROMPT = PromptTemplate(\n",
    "    template=prompt_template, \n",
    "    input_variables=[\"context\", \"question\"]\n",
    ")\n",
    "\n",
    "questions = [\n",
    "    \"Mention the job title using less than four words.\",\n",
    "    \"Mention the number of experience years needed for positions using less than six words.\",\n",
    "    \"Mention the academic qualification using less than ten words.\"\n",
    "]\n",
    "\n",
    "all_results = []\n",
    "\n",
    "# Use a set to keep track of processed file names\n",
    "processed_files = set()\n",
    "\n",
    "for doc in documents:\n",
    "    file_name_with_path = doc.metadata[\"source\"]\n",
    "    file_name = os.path.basename(file_name_with_path)\n",
    "    if file_name in processed_files:\n",
    "        continue  # Skip if already processed\n",
    "    processed_files.add(file_name)\n",
    "    \n",
    "    vectordb = FAISS.from_documents(\n",
    "        documents=[doc],\n",
    "        embedding=embeddings\n",
    "    )\n",
    "\n",
    "    retriever = vectordb.as_retriever()\n",
    "\n",
    "    chain = RetrievalQA.from_chain_type(\n",
    "        llm=llm,\n",
    "        chain_type=\"stuff\",\n",
    "        retriever=retriever,\n",
    "        input_key=\"query\",\n",
    "        return_source_documents=False,\n",
    "        chain_type_kwargs={\"prompt\": PROMPT}\n",
    "    )\n",
    "\n",
    "    # Dictionary to store the results for this document\n",
    "    results = {\n",
    "        \"Job title\": [],\n",
    "        \"Experienced years\": [],\n",
    "        \"Academic Qualification\": []\n",
    "    }\n",
    "\n",
    "    # Query each question and store the results\n",
    "    for question in questions:\n",
    "        result = chain({\"query\": question})\n",
    "        if question.startswith(\"Mention the job title\"):\n",
    "            results[\"Job title\"].append(result['result'])\n",
    "        elif question.startswith(\"Mention the number of experience years\"):\n",
    "            results[\"Experienced years\"].append(result['result'])\n",
    "        elif question.startswith(\"Mention the academic qualification\"):\n",
    "            results[\"Academic Qualification\"].append(result['result'])\n",
    "\n",
    "    # Add the results for this document to the list of all results\n",
    "    results[\"File\"] = file_name  # Store the file name without the path\n",
    "    all_results.append(results)\n",
    "\n",
    "# Convert all results to a DataFrame\n",
    "data = {\n",
    "    \"File\": [],\n",
    "    \"Job title\": [],\n",
    "    \"Experienced years\": [],\n",
    "    \"Academic Qualification\": []\n",
    "}\n",
    "\n",
    "for result in all_results:\n",
    "    data[\"File\"].append(result[\"File\"])\n",
    "    data[\"Job title\"].append(result[\"Job title\"])\n",
    "    data[\"Experienced years\"].append(result[\"Experienced years\"])\n",
    "    data[\"Academic Qualification\"].append(result[\"Academic Qualification\"])\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "print(df)\n",
    "\n",
    "print(\"\\nAcademic Qualification:\")\n",
    "for qualification in df[\"Academic Qualification\"]:\n",
    "    print(qualification)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of documents loaded: 17\n",
      "Document metadata: {'source': 'D:\\\\Data Science\\\\Generative_AI\\\\Resume_reader\\\\Amber-Barnes-Resume.pdf', 'file_path': 'D:\\\\Data Science\\\\Generative_AI\\\\Resume_reader\\\\Amber-Barnes-Resume.pdf', 'page': 0, 'total_pages': 2, 'format': 'PDF 1.5', 'title': 'Print', 'author': '', 'subject': '', 'keywords': '', 'creator': 'Adobe Illustrator CC 22.1 (Macintosh)', 'producer': 'Adobe PDF library 10.01', 'creationDate': \"D:20180907183739-05'00'\", 'modDate': \"D:20180909142342-05'00'\", 'trapped': ''}\n",
      "Document metadata: {'source': 'D:\\\\Data Science\\\\Generative_AI\\\\Resume_reader\\\\Amber-Barnes-Resume.pdf', 'file_path': 'D:\\\\Data Science\\\\Generative_AI\\\\Resume_reader\\\\Amber-Barnes-Resume.pdf', 'page': 1, 'total_pages': 2, 'format': 'PDF 1.5', 'title': 'Print', 'author': '', 'subject': '', 'keywords': '', 'creator': 'Adobe Illustrator CC 22.1 (Macintosh)', 'producer': 'Adobe PDF library 10.01', 'creationDate': \"D:20180907183739-05'00'\", 'modDate': \"D:20180909142342-05'00'\", 'trapped': ''}\n",
      "Document metadata: {'source': 'D:\\\\Data Science\\\\Generative_AI\\\\Resume_reader\\\\CHRISTOPHER MORGAN.pdf', 'file_path': 'D:\\\\Data Science\\\\Generative_AI\\\\Resume_reader\\\\CHRISTOPHER MORGAN.pdf', 'page': 0, 'total_pages': 1, 'format': 'PDF 1.7', 'title': '', 'author': 'Turbo', 'subject': '', 'keywords': '', 'creator': 'Microsoft® Word for Microsoft 365', 'producer': 'Microsoft® Word for Microsoft 365', 'creationDate': \"D:20240612224732+05'30'\", 'modDate': \"D:20240612224732+05'30'\", 'trapped': ''}\n",
      "Document metadata: {'source': 'D:\\\\Data Science\\\\Generative_AI\\\\Resume_reader\\\\George Evans.pdf', 'file_path': 'D:\\\\Data Science\\\\Generative_AI\\\\Resume_reader\\\\George Evans.pdf', 'page': 0, 'total_pages': 1, 'format': 'PDF 1.7', 'title': '', 'author': 'Konto Microsoft', 'subject': '', 'keywords': '', 'creator': 'Microsoft® Word for Microsoft 365', 'producer': 'Microsoft® Word for Microsoft 365', 'creationDate': \"D:20240613082323+05'30'\", 'modDate': \"D:20240613082323+05'30'\", 'trapped': ''}\n",
      "Document metadata: {'source': 'D:\\\\Data Science\\\\Generative_AI\\\\Resume_reader\\\\Jacob Ford_resume.pdf', 'file_path': 'D:\\\\Data Science\\\\Generative_AI\\\\Resume_reader\\\\Jacob Ford_resume.pdf', 'page': 0, 'total_pages': 2, 'format': 'PDF 1.7', 'title': '', 'author': 'Microsoft Office User', 'subject': '', 'keywords': '', 'creator': 'Microsoft Word', 'producer': '', 'creationDate': \"D:20231110055753+00'00'\", 'modDate': \"D:20231110055753+00'00'\", 'trapped': ''}\n",
      "Document metadata: {'source': 'D:\\\\Data Science\\\\Generative_AI\\\\Resume_reader\\\\Jacob Ford_resume.pdf', 'file_path': 'D:\\\\Data Science\\\\Generative_AI\\\\Resume_reader\\\\Jacob Ford_resume.pdf', 'page': 1, 'total_pages': 2, 'format': 'PDF 1.7', 'title': '', 'author': 'Microsoft Office User', 'subject': '', 'keywords': '', 'creator': 'Microsoft Word', 'producer': '', 'creationDate': \"D:20231110055753+00'00'\", 'modDate': \"D:20231110055753+00'00'\", 'trapped': ''}\n",
      "Document metadata: {'source': 'D:\\\\Data Science\\\\Generative_AI\\\\Resume_reader\\\\Jane Corsair.pdf', 'file_path': 'D:\\\\Data Science\\\\Generative_AI\\\\Resume_reader\\\\Jane Corsair.pdf', 'page': 0, 'total_pages': 1, 'format': 'PDF 1.7', 'title': 'environmental-resume-updated-0923-example', 'author': '', 'subject': '', 'keywords': 'WCAG 2.0', 'creator': '', 'producer': 'Equidox 5', 'creationDate': '', 'modDate': '', 'trapped': ''}\n",
      "Document metadata: {'source': 'D:\\\\Data Science\\\\Generative_AI\\\\Resume_reader\\\\Mark A Taylor.pdf', 'file_path': 'D:\\\\Data Science\\\\Generative_AI\\\\Resume_reader\\\\Mark A Taylor.pdf', 'page': 0, 'total_pages': 2, 'format': 'PDF 1.4', 'title': 'Mark Taylor - Resume', 'author': 'Mark Taylor', 'subject': '', 'keywords': '', 'creator': 'Word', 'producer': 'Mac OS X 10.10.5 Quartz PDFContext', 'creationDate': \"D:20171221151959Z00'00'\", 'modDate': \"D:20171221151959Z00'00'\", 'trapped': ''}\n",
      "Document metadata: {'source': 'D:\\\\Data Science\\\\Generative_AI\\\\Resume_reader\\\\Mark A Taylor.pdf', 'file_path': 'D:\\\\Data Science\\\\Generative_AI\\\\Resume_reader\\\\Mark A Taylor.pdf', 'page': 1, 'total_pages': 2, 'format': 'PDF 1.4', 'title': 'Mark Taylor - Resume', 'author': 'Mark Taylor', 'subject': '', 'keywords': '', 'creator': 'Word', 'producer': 'Mac OS X 10.10.5 Quartz PDFContext', 'creationDate': \"D:20171221151959Z00'00'\", 'modDate': \"D:20171221151959Z00'00'\", 'trapped': ''}\n",
      "Document metadata: {'source': 'D:\\\\Data Science\\\\Generative_AI\\\\Resume_reader\\\\Nanthakumaran S.pdf', 'file_path': 'D:\\\\Data Science\\\\Generative_AI\\\\Resume_reader\\\\Nanthakumaran S.pdf', 'page': 0, 'total_pages': 1, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'creator': 'LaTeX with hyperref', 'producer': 'xdvipdfmx (20211117)', 'creationDate': \"D:20230617153227-00'00'\", 'modDate': '', 'trapped': ''}\n",
      "Document metadata: {'source': 'D:\\\\Data Science\\\\Generative_AI\\\\Resume_reader\\\\ROBERT RICHARDSON.pdf', 'file_path': 'D:\\\\Data Science\\\\Generative_AI\\\\Resume_reader\\\\ROBERT RICHARDSON.pdf', 'page': 0, 'total_pages': 2, 'format': 'PDF 1.7', 'title': '', 'author': 'Konto Microsoft', 'subject': '', 'keywords': '', 'creator': 'Microsoft® Word for Microsoft 365', 'producer': 'Microsoft® Word for Microsoft 365', 'creationDate': \"D:20240612224825+05'30'\", 'modDate': \"D:20240612224825+05'30'\", 'trapped': ''}\n",
      "Document metadata: {'source': 'D:\\\\Data Science\\\\Generative_AI\\\\Resume_reader\\\\ROBERT RICHARDSON.pdf', 'file_path': 'D:\\\\Data Science\\\\Generative_AI\\\\Resume_reader\\\\ROBERT RICHARDSON.pdf', 'page': 1, 'total_pages': 2, 'format': 'PDF 1.7', 'title': '', 'author': 'Konto Microsoft', 'subject': '', 'keywords': '', 'creator': 'Microsoft® Word for Microsoft 365', 'producer': 'Microsoft® Word for Microsoft 365', 'creationDate': \"D:20240612224825+05'30'\", 'modDate': \"D:20240612224825+05'30'\", 'trapped': ''}\n",
      "Document metadata: {'source': 'D:\\\\Data Science\\\\Generative_AI\\\\Resume_reader\\\\Susan Williams.pdf', 'file_path': 'D:\\\\Data Science\\\\Generative_AI\\\\Resume_reader\\\\Susan Williams.pdf', 'page': 0, 'total_pages': 1, 'format': 'PDF 1.7', 'title': '', 'author': 'Turbo', 'subject': '', 'keywords': '', 'creator': 'Microsoft® Word for Microsoft 365', 'producer': 'Microsoft® Word for Microsoft 365', 'creationDate': \"D:20240613082413+05'30'\", 'modDate': \"D:20240613082413+05'30'\", 'trapped': ''}\n",
      "Document metadata: {'source': 'D:\\\\Data Science\\\\Generative_AI\\\\Resume_reader\\\\Terry-Mipro-Resume.pdf', 'file_path': 'D:\\\\Data Science\\\\Generative_AI\\\\Resume_reader\\\\Terry-Mipro-Resume.pdf', 'page': 0, 'total_pages': 2, 'format': 'PDF 1.5', 'title': '', 'author': 'tntsquar@bellsouth.net', 'subject': '', 'keywords': '', 'creator': 'Microsoft® Word 2010', 'producer': 'Microsoft® Word 2010', 'creationDate': \"D:20171106125543-06'00'\", 'modDate': \"D:20171106125543-06'00'\", 'trapped': ''}\n",
      "Document metadata: {'source': 'D:\\\\Data Science\\\\Generative_AI\\\\Resume_reader\\\\Terry-Mipro-Resume.pdf', 'file_path': 'D:\\\\Data Science\\\\Generative_AI\\\\Resume_reader\\\\Terry-Mipro-Resume.pdf', 'page': 1, 'total_pages': 2, 'format': 'PDF 1.5', 'title': '', 'author': 'tntsquar@bellsouth.net', 'subject': '', 'keywords': '', 'creator': 'Microsoft® Word 2010', 'producer': 'Microsoft® Word 2010', 'creationDate': \"D:20171106125543-06'00'\", 'modDate': \"D:20171106125543-06'00'\", 'trapped': ''}\n",
      "Document metadata: {'source': 'D:\\\\Data Science\\\\Generative_AI\\\\Resume_reader\\\\TINA BROWN.pdf', 'file_path': 'D:\\\\Data Science\\\\Generative_AI\\\\Resume_reader\\\\TINA BROWN.pdf', 'page': 0, 'total_pages': 2, 'format': 'PDF 1.3', 'title': 'Microsoft Word - CEO Resume_SAMPLE for CDI (from JBP).doc', 'author': '', 'subject': '', 'keywords': '', 'creator': 'Word', 'producer': 'macOS Version 11.5.2 (Build 20G95) Quartz PDFContext', 'creationDate': \"D:20220125223852Z00'00'\", 'modDate': \"D:20220125223852Z00'00'\", 'trapped': ''}\n",
      "Document metadata: {'source': 'D:\\\\Data Science\\\\Generative_AI\\\\Resume_reader\\\\TINA BROWN.pdf', 'file_path': 'D:\\\\Data Science\\\\Generative_AI\\\\Resume_reader\\\\TINA BROWN.pdf', 'page': 1, 'total_pages': 2, 'format': 'PDF 1.3', 'title': 'Microsoft Word - CEO Resume_SAMPLE for CDI (from JBP).doc', 'author': '', 'subject': '', 'keywords': '', 'creator': 'Word', 'producer': 'macOS Version 11.5.2 (Build 20G95) Quartz PDFContext', 'creationDate': \"D:20220125223852Z00'00'\", 'modDate': \"D:20220125223852Z00'00'\", 'trapped': ''}\n",
      "load INSTRUCTOR_Transformer\n",
      "max_seq_length  512\n",
      "First DataFrame (File and Experienced years):\n",
      "                       File                                  Experienced years\n",
      "0   Amber-Barnes-Resume.pdf  [\\n\\n1. Animal Welfare Consultant - 8 years\\n2...\n",
      "1    CHRISTOPHER MORGAN.pdf  [\\n\\nAnswer: \\n- Web Developer (09/2015 to 05/...\n",
      "2          George Evans.pdf  [\\n\\n1. Senior Web Developer - 4 years\\n2. Web...\n",
      "3     Jacob Ford_resume.pdf  [\\n\\n1. Plumbing work experience at O'Brien Pl...\n",
      "4          Jane Corsair.pdf  [\\n\\n1. Science Intern - 6 months\\n2. Animal C...\n",
      "5         Mark A Taylor.pdf  [\\n\\n- Director of Corporate Risk Management\\n...\n",
      "6       Nanthakumaran S.pdf  [\\n\\n1. Associate Engineer Trainee at Presidio...\n",
      "7     ROBERT RICHARDSON.pdf  [\\n\\n1. Real Estate Agent at XYZ Realty, Anyto...\n",
      "8        Susan Williams.pdf  [\\n\\n1. Store Manager at LUXURY CAR CENTER fro...\n",
      "9    Terry-Mipro-Resume.pdf  [\\n\\n1. Manager - 2 years\\n2. Internal Auditor...\n",
      "10           TINA BROWN.pdf  [\\n\\n1. CEO, C-SUITE EXEC\\n2. CHIEF EXECUTIVE ...\n",
      "Second DataFrame (File and Academic Qualification):\n",
      "                       File                             Academic Qualification\n",
      "0   Amber-Barnes-Resume.pdf  [\\n\\n- MSc in Animal Welfare, Ethics, and Advo...\n",
      "1    CHRISTOPHER MORGAN.pdf  [\\n\\n- Bachelor of Science: Computer Informati...\n",
      "2          George Evans.pdf  [\\n\\n- Bachelor of Science: Computer Informati...\n",
      "3     Jacob Ford_resume.pdf  [\\n\\n1. Completed 2023 TAFE Qld, Acacia Ridge ...\n",
      "4          Jane Corsair.pdf  [\\n\\n1. Associate of Arts in General Science f...\n",
      "5         Mark A Taylor.pdf  [\\n\\n- BS in Manufacturing Engineering Technol...\n",
      "6       Nanthakumaran S.pdf  [\\n\\n1. B.E. in Electronics and Communication ...\n",
      "7     ROBERT RICHARDSON.pdf  [\\n\\nThere are no academic qualifications ment...\n",
      "8        Susan Williams.pdf  [\\n\\n1. Bachelor of Science: Automotive Techno...\n",
      "9    Terry-Mipro-Resume.pdf  [\\n\\n1. Certified Public Accountant (CPA)\\n2. ...\n",
      "10           TINA BROWN.pdf  [\\n\\n1. Bachelor's degree in Business Administ...\n"
     ]
    },
    {
     "ename": "PermissionError",
     "evalue": "[Errno 13] Permission denied: 'output_experienced_years1.xlsx'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPermissionError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 118\u001b[0m\n\u001b[0;32m    115\u001b[0m \u001b[38;5;28mprint\u001b[39m(df2)\n\u001b[0;32m    117\u001b[0m excel_file_path1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput_experienced_years1.xlsx\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m--> 118\u001b[0m \u001b[43mdf1\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_excel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexcel_file_path1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    120\u001b[0m excel_file_path2 \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput_academic_qualification1.xlsx\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    121\u001b[0m df2\u001b[38;5;241m.\u001b[39mto_excel(excel_file_path2, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\pandas\\util\\_decorators.py:333\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    327\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[0;32m    328\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    329\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[0;32m    330\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[0;32m    331\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[0;32m    332\u001b[0m     )\n\u001b[1;32m--> 333\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\pandas\\core\\generic.py:2417\u001b[0m, in \u001b[0;36mNDFrame.to_excel\u001b[1;34m(self, excel_writer, sheet_name, na_rep, float_format, columns, header, index, index_label, startrow, startcol, engine, merge_cells, inf_rep, freeze_panes, storage_options, engine_kwargs)\u001b[0m\n\u001b[0;32m   2404\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mio\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mformats\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexcel\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ExcelFormatter\n\u001b[0;32m   2406\u001b[0m formatter \u001b[38;5;241m=\u001b[39m ExcelFormatter(\n\u001b[0;32m   2407\u001b[0m     df,\n\u001b[0;32m   2408\u001b[0m     na_rep\u001b[38;5;241m=\u001b[39mna_rep,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2415\u001b[0m     inf_rep\u001b[38;5;241m=\u001b[39minf_rep,\n\u001b[0;32m   2416\u001b[0m )\n\u001b[1;32m-> 2417\u001b[0m \u001b[43mformatter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2418\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexcel_writer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2419\u001b[0m \u001b[43m    \u001b[49m\u001b[43msheet_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msheet_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2420\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstartrow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstartrow\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2421\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstartcol\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstartcol\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2422\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfreeze_panes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfreeze_panes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2423\u001b[0m \u001b[43m    \u001b[49m\u001b[43mengine\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2424\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2425\u001b[0m \u001b[43m    \u001b[49m\u001b[43mengine_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mengine_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2426\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\pandas\\io\\formats\\excel.py:943\u001b[0m, in \u001b[0;36mExcelFormatter.write\u001b[1;34m(self, writer, sheet_name, startrow, startcol, freeze_panes, engine, storage_options, engine_kwargs)\u001b[0m\n\u001b[0;32m    941\u001b[0m     need_save \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    942\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 943\u001b[0m     writer \u001b[38;5;241m=\u001b[39m \u001b[43mExcelWriter\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    944\u001b[0m \u001b[43m        \u001b[49m\u001b[43mwriter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    945\u001b[0m \u001b[43m        \u001b[49m\u001b[43mengine\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    946\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    947\u001b[0m \u001b[43m        \u001b[49m\u001b[43mengine_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mengine_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    948\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    949\u001b[0m     need_save \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    951\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\pandas\\io\\excel\\_openpyxl.py:61\u001b[0m, in \u001b[0;36mOpenpyxlWriter.__init__\u001b[1;34m(self, path, engine, date_format, datetime_format, mode, storage_options, if_sheet_exists, engine_kwargs, **kwargs)\u001b[0m\n\u001b[0;32m     57\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mopenpyxl\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mworkbook\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Workbook\n\u001b[0;32m     59\u001b[0m engine_kwargs \u001b[38;5;241m=\u001b[39m combine_kwargs(engine_kwargs, kwargs)\n\u001b[1;32m---> 61\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m     62\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     63\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     64\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     65\u001b[0m \u001b[43m    \u001b[49m\u001b[43mif_sheet_exists\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mif_sheet_exists\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     66\u001b[0m \u001b[43m    \u001b[49m\u001b[43mengine_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mengine_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     67\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     69\u001b[0m \u001b[38;5;66;03m# ExcelWriter replaced \"a\" by \"r+\" to allow us to first read the excel file from\u001b[39;00m\n\u001b[0;32m     70\u001b[0m \u001b[38;5;66;03m# the file and later write to it\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr+\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mode:  \u001b[38;5;66;03m# Load from existing workbook\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\pandas\\io\\excel\\_base.py:1246\u001b[0m, in \u001b[0;36mExcelWriter.__init__\u001b[1;34m(self, path, engine, date_format, datetime_format, mode, storage_options, if_sheet_exists, engine_kwargs)\u001b[0m\n\u001b[0;32m   1242\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handles \u001b[38;5;241m=\u001b[39m IOHandles(\n\u001b[0;32m   1243\u001b[0m     cast(IO[\u001b[38;5;28mbytes\u001b[39m], path), compression\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28;01mNone\u001b[39;00m}\n\u001b[0;32m   1244\u001b[0m )\n\u001b[0;32m   1245\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(path, ExcelWriter):\n\u001b[1;32m-> 1246\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1247\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\n\u001b[0;32m   1248\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1249\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cur_sheet \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1251\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m date_format \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\pandas\\io\\common.py:882\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[0;32m    874\u001b[0m             handle,\n\u001b[0;32m    875\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    878\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    879\u001b[0m         )\n\u001b[0;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m--> 882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    883\u001b[0m     handles\u001b[38;5;241m.\u001b[39mappend(handle)\n\u001b[0;32m    885\u001b[0m \u001b[38;5;66;03m# Convert BytesIO or file objects passed with an encoding\u001b[39;00m\n",
      "\u001b[1;31mPermissionError\u001b[0m: [Errno 13] Permission denied: 'output_experienced_years1.xlsx'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "from langchain_openai import OpenAI\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_community.document_loaders import DirectoryLoader, PyMuPDFLoader\n",
    "from langchain_community.embeddings import HuggingFaceInstructEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "llm = OpenAI(temperature=0, max_tokens=500)\n",
    "\n",
    "folder_path = 'D:\\\\Data Science\\\\Generative_AI\\\\Resume_reader'\n",
    "loader = DirectoryLoader(folder_path, glob='*.pdf', loader_cls=PyMuPDFLoader)\n",
    "documents = loader.load()\n",
    "\n",
    "print(f\"Number of documents loaded: {len(documents)}\")\n",
    "for doc in documents:\n",
    "    print(f\"Document metadata: {doc.metadata}\")\n",
    "\n",
    "embeddings = HuggingFaceInstructEmbeddings()\n",
    "\n",
    "prompt_template = \"\"\"\n",
    "You are a resume information extractor. Given the following context and a question, \n",
    "generate an proper answer based on this context only.\n",
    "If there are several work experiences with jobs(the jobs done previously) or several academic qualifications(Educational) in one pdf file, \n",
    "provide a list of those answers.\n",
    "Most of the time there should be an answer. Extract from the given text don't try to modify the answers.\n",
    "\n",
    "CONTEXT: {context}\n",
    "\n",
    "QUESTION: {question}\"\"\"\n",
    "\n",
    "PROMPT = PromptTemplate(\n",
    "    template=prompt_template, \n",
    "    input_variables=[\"context\", \"question\"]\n",
    ")\n",
    "\n",
    "questions = [\n",
    "    \"Mention the number of experienced years with the relavant position names as a list.\",\n",
    "    \"Mention the academic qualifications as a list.\"\n",
    "]\n",
    "\n",
    "all_results = []\n",
    "\n",
    "# Use a set to keep track of processed file names\n",
    "processed_files = set()\n",
    "\n",
    "for doc in documents:\n",
    "    file_name_with_path = doc.metadata[\"source\"]\n",
    "    file_name = os.path.basename(file_name_with_path)\n",
    "    if file_name in processed_files:\n",
    "        continue  # Skip if already processed\n",
    "    processed_files.add(file_name)\n",
    "    \n",
    "    vectordb = FAISS.from_documents(\n",
    "        documents=[doc],\n",
    "        embedding=embeddings\n",
    "    )\n",
    "\n",
    "    retriever = vectordb.as_retriever()\n",
    "\n",
    "    chain = RetrievalQA.from_chain_type(\n",
    "        llm=llm,\n",
    "        chain_type=\"stuff\",\n",
    "        retriever=retriever,\n",
    "        input_key=\"query\",\n",
    "        return_source_documents=False,\n",
    "        chain_type_kwargs={\"prompt\": PROMPT}\n",
    "    )\n",
    "\n",
    "    # Dictionary to store the results for this document\n",
    "    results = {\n",
    "        \"Experienced years\": [],\n",
    "        \"Academic Qualification\": []\n",
    "    }\n",
    "\n",
    "    # Query each question and store the results\n",
    "    for question in questions:\n",
    "        result = chain({\"query\": question})\n",
    "        if question.startswith(\"Mention the number of experienced years\"):\n",
    "            results[\"Experienced years\"].append(result['result'])\n",
    "        elif question.startswith(\"Mention the academic qualifications\"):\n",
    "            results[\"Academic Qualification\"].append(result['result'])\n",
    "\n",
    "    # Add the results for this document to the list of all results\n",
    "    results[\"File\"] = file_name  # Store the file name without the path\n",
    "    all_results.append(results)\n",
    "\n",
    "data1 = {\n",
    "    \"File\": [],\n",
    "    \"Experienced years\": []\n",
    "}\n",
    "\n",
    "data2 = {\n",
    "    \"File\": [],\n",
    "    \"Academic Qualification\": []\n",
    "}\n",
    "\n",
    "for result in all_results:\n",
    "    data1[\"File\"].append(result[\"File\"])\n",
    "    data1[\"Experienced years\"].append(result[\"Experienced years\"])\n",
    "    data2[\"File\"].append(result[\"File\"])\n",
    "    data2[\"Academic Qualification\"].append(result[\"Academic Qualification\"])\n",
    "\n",
    "df1 = pd.DataFrame(data1)\n",
    "df2 = pd.DataFrame(data2)\n",
    "\n",
    "print(\"First DataFrame (File and Experienced years):\")\n",
    "print(df1)\n",
    "\n",
    "print(\"Second DataFrame (File and Academic Qualification):\")\n",
    "print(df2)\n",
    "\n",
    "excel_file_path1 = \"output_experienced_years1.xlsx\"\n",
    "df1.to_excel(excel_file_path1, index=False)\n",
    "\n",
    "excel_file_path2 = \"output_academic_qualification1.xlsx\"\n",
    "df2.to_excel(excel_file_path2, index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarity Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
