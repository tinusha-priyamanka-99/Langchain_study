{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_openai import OpenAI\n",
    "from langchain_community.document_loaders import TextLoader, DirectoryLoader\n",
    "from langchain.embeddings import HuggingFaceInstructEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.chains import RetrievalQA \n",
    "from langchain.prompts import PromptTemplate\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load INSTRUCTOR_Transformer\n",
      "max_seq_length  512\n"
     ]
    }
   ],
   "source": [
    "llm = OpenAI(temperature=0.6, max_tokens=500)\n",
    "\n",
    "folder_path = 'D:\\\\Data Science\\\\Generative_AI\\\\Resume reader'\n",
    "loader = DirectoryLoader(folder_path, glob='*.txt', loader_cls=TextLoader)\n",
    "documents = loader.load()\n",
    "\n",
    "embeddings = HuggingFaceInstructEmbeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectordb = FAISS.from_documents(\n",
    "    documents=documents,\n",
    "    embedding=embeddings\n",
    ")\n",
    "\n",
    "retriever = vectordb.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer:  {'query': 'Mention the required academic qualification', 'result': \" for Senior Data Scientist\\n\\nMaster's Degree in Computer Science, Statistics, Math, Operations Research, Economics, or a related field.\"}\n"
     ]
    }
   ],
   "source": [
    "prompt_template = \"\"\"Given the following context and a question, generate an answer using minimum number of words based on this context only.\n",
    "    In the answer try to provide as much text as possible from \"response\" section in the source document context without making much changes.\n",
    "    If the answer is not found in the context, kindly state \"I don't know.\" Don't try to make up an answer.\n",
    "\n",
    "    CONTEXT: {context}\n",
    "\n",
    "    QUESTION: {question}\"\"\"\n",
    "\n",
    "PROMPT = PromptTemplate(\n",
    "        template=prompt_template, \n",
    "        input_variables=[\"context\", \"question\"]\n",
    "    )\n",
    "\n",
    "chain = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    chain_type=\"stuff\",\n",
    "    retriever=retriever,\n",
    "    input_key=\"query\",\n",
    "    return_source_documents=False,\n",
    "    chain_type_kwargs={\"prompt\": PROMPT})\n",
    "\n",
    "result = chain(\"Mention the required academic qualification\")\n",
    "print(\"Answer: \",result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load INSTRUCTOR_Transformer\n",
      "max_seq_length  512\n",
      "       File                             Job title        Experienced years  \\\n",
      "0  JD_1.txt                         [\\n\\nAnalyst]         [\\n\\n1-2 years.]   \n",
      "1  JD_2.txt           [\\n\\nSenior Data Scientist]  [\\n\\nAt least 2 years.]   \n",
      "2  JD_3.txt  [\\n\\nBusiness Development Associate]      [\\n\\nI don't know.]   \n",
      "3  JD_4.txt                  [\\n\\nData Scientist]  [\\n\\nAt least 2 years.]   \n",
      "4  JD_5.txt                 [\\n\\nProcess Analyst]          [\\n\\n0-3 years]   \n",
      "\n",
      "                              Academic Qualification  \n",
      "0  [\\n\\nGraduate in science/business/accounting o...  \n",
      "1  [\\n\\nMaster's Degree in Computer Science, Stat...  \n",
      "2         [\\nBusiness, Marketing, or related field.]  \n",
      "3  [\\n\\nMaster's Degree in Computer Science, Stat...  \n",
      "4  [\\n\\nAny Graduate (Arts/science/commerce/busin...  \n",
      "\n",
      "Academic Qualification:\n",
      "['\\n\\nGraduate in science/business/accounting or CIMA/CA.']\n",
      "[\"\\n\\nMaster's Degree in Computer Science, Statistics, Math, or related field.\"]\n",
      "['\\nBusiness, Marketing, or related field.']\n",
      "[\"\\n\\nMaster's Degree in Computer Science, Statistics, or related field.\"]\n",
      "['\\n\\nAny Graduate (Arts/science/commerce/business)']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "from langchain_openai import OpenAI\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_community.document_loaders import DirectoryLoader, TextLoader\n",
    "from langchain_community.embeddings import HuggingFaceInstructEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "llm = OpenAI(temperature=0.6, max_tokens=500)\n",
    "\n",
    "folder_path = 'D:\\\\Data Science\\\\Generative_AI\\\\Resume reader'\n",
    "loader = DirectoryLoader(folder_path, glob='*.txt', loader_cls=TextLoader)\n",
    "documents = loader.load()\n",
    "\n",
    "embeddings = HuggingFaceInstructEmbeddings()\n",
    "\n",
    "prompt_template = \"\"\"Given the following context and a question, generate an answer using minimum number of words based on this context only.\n",
    "    In the answer try to provide as much text as possible from \"response\" section in the source document context without making much changes.\n",
    "    If the answer is not found in the context, kindly state \"I don't know.\" Don't try to make up an answer.\n",
    "\n",
    "    CONTEXT: {context}\n",
    "\n",
    "    QUESTION: {question}\"\"\"\n",
    "\n",
    "PROMPT = PromptTemplate(\n",
    "    template=prompt_template, \n",
    "    input_variables=[\"context\", \"question\"]\n",
    ")\n",
    "\n",
    "questions = [\n",
    "    \"Mention the job title using less than four words.\",\n",
    "    \"Mention the number of experience years needed for positions using less than six words.\",\n",
    "    \"Mention the academic qualification using less than ten words.\"\n",
    "]\n",
    "\n",
    "\n",
    "all_results = []\n",
    "\n",
    "for doc in documents:\n",
    "    vectordb = FAISS.from_documents(\n",
    "        documents=[doc],\n",
    "        embedding=embeddings\n",
    "    )\n",
    "\n",
    "    retriever = vectordb.as_retriever()\n",
    "\n",
    "    chain = RetrievalQA.from_chain_type(\n",
    "        llm=llm,\n",
    "        chain_type=\"stuff\",\n",
    "        retriever=retriever,\n",
    "        input_key=\"query\",\n",
    "        return_source_documents=False,\n",
    "        chain_type_kwargs={\"prompt\": PROMPT}\n",
    "    )\n",
    "\n",
    "    # Dictionary to store the results for this document\n",
    "    results = {\n",
    "        \"Job title\": [],\n",
    "        \"Experienced years\": [],\n",
    "        \"Academic Qualification\": []\n",
    "    }\n",
    "\n",
    "    # Query each question and store the results\n",
    "    for question in questions:\n",
    "        result = chain({\"query\": question})\n",
    "        if question.startswith(\"Mention the job title\"):\n",
    "            results[\"Job title\"].append(result['result'])\n",
    "        elif question.startswith(\"Mention the number of experience years\"):\n",
    "            results[\"Experienced years\"].append(result['result'])\n",
    "        elif question.startswith(\"Mention the academic qualification\"):\n",
    "            results[\"Academic Qualification\"].append(result['result'])\n",
    "\n",
    "    # Add the results for this document to the list of all results\n",
    "    all_results.append(results)\n",
    "\n",
    "# Convert all results to a DataFrame\n",
    "data = {\n",
    "    \"File\": [],\n",
    "    \"Job title\": [],\n",
    "    \"Experienced years\": [],\n",
    "    \"Academic Qualification\": []\n",
    "}\n",
    "\n",
    "for i, result in enumerate(all_results):\n",
    "    data[\"File\"].append(f'JD_{i+1}.txt')\n",
    "    data[\"Job title\"].append(result[\"Job title\"])\n",
    "    data[\"Experienced years\"].append(result[\"Experienced years\"])\n",
    "    data[\"Academic Qualification\"].append(result[\"Academic Qualification\"])\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Print the DataFrame\n",
    "print(df)\n",
    "\n",
    "print(\"\\nAcademic Qualification:\")\n",
    "for qualification in df[\"Academic Qualification\"]:\n",
    "    print(qualification)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of documents loaded: 5\n",
      "Document metadata: {'source': 'D:\\\\Data Science\\\\Generative_AI\\\\Resume reader\\\\Anthony Davies_Resume.pdf', 'file_path': 'D:\\\\Data Science\\\\Generative_AI\\\\Resume reader\\\\Anthony Davies_Resume.pdf', 'page': 0, 'total_pages': 1, 'format': 'PDF 1.7', 'title': '', 'author': 'Turbo', 'subject': '', 'keywords': '', 'creator': 'Microsoft® Word for Microsoft 365', 'producer': 'Microsoft® Word for Microsoft 365', 'creationDate': \"D:20240302172612+05'30'\", 'modDate': \"D:20240302172612+05'30'\", 'trapped': ''}\n",
      "Document metadata: {'source': 'D:\\\\Data Science\\\\Generative_AI\\\\Resume reader\\\\Christoper Morgan_Resume.pdf', 'file_path': 'D:\\\\Data Science\\\\Generative_AI\\\\Resume reader\\\\Christoper Morgan_Resume.pdf', 'page': 0, 'total_pages': 1, 'format': 'PDF 1.7', 'title': '', 'author': 'Turbo', 'subject': '', 'keywords': '', 'creator': 'Microsoft® Word for Microsoft 365', 'producer': 'Microsoft® Word for Microsoft 365', 'creationDate': \"D:20240302170323+05'30'\", 'modDate': \"D:20240302170323+05'30'\", 'trapped': ''}\n",
      "Document metadata: {'source': 'D:\\\\Data Science\\\\Generative_AI\\\\Resume reader\\\\Layney Spencer_Resume.pdf', 'file_path': 'D:\\\\Data Science\\\\Generative_AI\\\\Resume reader\\\\Layney Spencer_Resume.pdf', 'page': 0, 'total_pages': 2, 'format': 'PDF 1.3', 'title': 'Assistant Director', 'author': '', 'subject': '', 'keywords': '', 'creator': 'react-pdf', 'producer': 'react-pdf', 'creationDate': 'D:20220201110147Z', 'modDate': '', 'trapped': ''}\n",
      "Document metadata: {'source': 'D:\\\\Data Science\\\\Generative_AI\\\\Resume reader\\\\Layney Spencer_Resume.pdf', 'file_path': 'D:\\\\Data Science\\\\Generative_AI\\\\Resume reader\\\\Layney Spencer_Resume.pdf', 'page': 1, 'total_pages': 2, 'format': 'PDF 1.3', 'title': 'Assistant Director', 'author': '', 'subject': '', 'keywords': '', 'creator': 'react-pdf', 'producer': 'react-pdf', 'creationDate': 'D:20220201110147Z', 'modDate': '', 'trapped': ''}\n",
      "Document metadata: {'source': 'D:\\\\Data Science\\\\Generative_AI\\\\Resume reader\\\\Susan Williams_Resume.pdf', 'file_path': 'D:\\\\Data Science\\\\Generative_AI\\\\Resume reader\\\\Susan Williams_Resume.pdf', 'page': 0, 'total_pages': 1, 'format': 'PDF 1.7', 'title': '', 'author': 'Turbo', 'subject': '', 'keywords': '', 'creator': 'Microsoft® Word for Microsoft 365', 'producer': 'Microsoft® Word for Microsoft 365', 'creationDate': \"D:20240302172843+05'30'\", 'modDate': \"D:20240302172843+05'30'\", 'trapped': ''}\n",
      "load INSTRUCTOR_Transformer\n",
      "max_seq_length  512\n",
      "                           File                 Job title  \\\n",
      "0     Anthony Davies_Resume.pdf       [\\n\\nWeb Developer]   \n",
      "1  Christoper Morgan_Resume.pdf       [\\n\\nWeb Developer]   \n",
      "2     Layney Spencer_Resume.pdf  [\\n\\nAssistant Director]   \n",
      "3     Susan Williams_Resume.pdf       [\\n\\nStore Manager]   \n",
      "\n",
      "          Experienced years                             Academic Qualification  \n",
      "0             [\\n\\n2 years]  [\\n\\nBachelor of Science in Computer Informati...  \n",
      "1         [\\n\\nFour years.]  [\\n\\nBachelor of Science in Computer Informati...  \n",
      "2            [\\n\\n14 years]         [\\n\\nMaster's in Business Administration.]  \n",
      "3  [\\n\\n4 years and 1 year]  [\\n\\nBachelor of Science in Automotive Technol...  \n",
      "\n",
      "Academic Qualification:\n",
      "['\\n\\nBachelor of Science in Computer Information Systems.']\n",
      "['\\n\\nBachelor of Science in Computer Information Systems.']\n",
      "[\"\\n\\nMaster's in Business Administration.\"]\n",
      "['\\n\\nBachelor of Science in Automotive Technology.']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "from langchain_openai import OpenAI\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_community.document_loaders import DirectoryLoader, PyMuPDFLoader\n",
    "from langchain_community.embeddings import HuggingFaceInstructEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "llm = OpenAI(temperature=0, max_tokens=500)\n",
    "\n",
    "folder_path = 'D:\\\\Data Science\\\\Generative_AI\\\\Resume reader'\n",
    "loader = DirectoryLoader(folder_path, glob='*.pdf', loader_cls=PyMuPDFLoader)\n",
    "documents = loader.load()\n",
    "\n",
    "# Print the loaded documents for debugging\n",
    "print(f\"Number of documents loaded: {len(documents)}\")\n",
    "for doc in documents:\n",
    "    print(f\"Document metadata: {doc.metadata}\")\n",
    "\n",
    "embeddings = HuggingFaceInstructEmbeddings()\n",
    "\n",
    "prompt_template = \"\"\"\n",
    "Given the following context and a question, generate an answer using minimum number of words based on this context only.\n",
    "In the answer try to provide as much text as possible from \"response\" section in the source document context without making much changes.\n",
    "If the answer is not found in the context, kindly state \"I don't know.\" Don't try to make up an answer.\n",
    "\n",
    "CONTEXT: {context}\n",
    "\n",
    "QUESTION: {question}\"\"\"\n",
    "\n",
    "PROMPT = PromptTemplate(\n",
    "    template=prompt_template, \n",
    "    input_variables=[\"context\", \"question\"]\n",
    ")\n",
    "\n",
    "questions = [\n",
    "    \"Mention the job title using less than four words.\",\n",
    "    \"Mention the number of experience years needed for positions using less than six words.\",\n",
    "    \"Mention the academic qualification using less than ten words.\"\n",
    "]\n",
    "\n",
    "all_results = []\n",
    "\n",
    "# Use a set to keep track of processed file names\n",
    "processed_files = set()\n",
    "\n",
    "for doc in documents:\n",
    "    file_name_with_path = doc.metadata[\"source\"]\n",
    "    file_name = os.path.basename(file_name_with_path)\n",
    "    if file_name in processed_files:\n",
    "        continue  # Skip if already processed\n",
    "    processed_files.add(file_name)\n",
    "    \n",
    "    vectordb = FAISS.from_documents(\n",
    "        documents=[doc],\n",
    "        embedding=embeddings\n",
    "    )\n",
    "\n",
    "    retriever = vectordb.as_retriever()\n",
    "\n",
    "    chain = RetrievalQA.from_chain_type(\n",
    "        llm=llm,\n",
    "        chain_type=\"stuff\",\n",
    "        retriever=retriever,\n",
    "        input_key=\"query\",\n",
    "        return_source_documents=False,\n",
    "        chain_type_kwargs={\"prompt\": PROMPT}\n",
    "    )\n",
    "\n",
    "    # Dictionary to store the results for this document\n",
    "    results = {\n",
    "        \"Job title\": [],\n",
    "        \"Experienced years\": [],\n",
    "        \"Academic Qualification\": []\n",
    "    }\n",
    "\n",
    "    # Query each question and store the results\n",
    "    for question in questions:\n",
    "        result = chain({\"query\": question})\n",
    "        if question.startswith(\"Mention the job title\"):\n",
    "            results[\"Job title\"].append(result['result'])\n",
    "        elif question.startswith(\"Mention the number of experience years\"):\n",
    "            results[\"Experienced years\"].append(result['result'])\n",
    "        elif question.startswith(\"Mention the academic qualification\"):\n",
    "            results[\"Academic Qualification\"].append(result['result'])\n",
    "\n",
    "    # Add the results for this document to the list of all results\n",
    "    results[\"File\"] = file_name  # Store the file name without the path\n",
    "    all_results.append(results)\n",
    "\n",
    "# Convert all results to a DataFrame\n",
    "data = {\n",
    "    \"File\": [],\n",
    "    \"Job title\": [],\n",
    "    \"Experienced years\": [],\n",
    "    \"Academic Qualification\": []\n",
    "}\n",
    "\n",
    "for result in all_results:\n",
    "    data[\"File\"].append(result[\"File\"])\n",
    "    data[\"Job title\"].append(result[\"Job title\"])\n",
    "    data[\"Experienced years\"].append(result[\"Experienced years\"])\n",
    "    data[\"Academic Qualification\"].append(result[\"Academic Qualification\"])\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "print(df)\n",
    "\n",
    "print(\"\\nAcademic Qualification:\")\n",
    "for qualification in df[\"Academic Qualification\"]:\n",
    "    print(qualification)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
